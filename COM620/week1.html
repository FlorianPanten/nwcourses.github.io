<html>
<head>
<title>Immersive Technologies - Topic 1</title>
<link rel='stylesheet' type='text/css' href='../css/dfti0910.css'>
</head>
<body>
<div class='titlebox'>
<h1>Immersive Technologies</h1>
<h2>Topic 1: Introduction to OpenGL and three.js</h2>
</div>
<hr />
<h2>Developing 3D Graphics in the Browser</h2>
<p>The key to developing immersive applications on the web is rendering <em>3D graphics</em> (such as shapes and 3D models) in the browser. 
To develop 3D applications you use a 3D graphics library. 
There are two commonly used 3D graphics libraries:
</p><ul>
<li><em><a href='https://opengl.org'>OpenGL</a></em> is the standard cross-platform API for 3D graphics. OpenGL was originally written in C and 
has been around since 1992, and was originally used on high-performance Unix
workstations provided by companies such as Silicon Graphics. Later it was
ported to other desktop environments such as Windows, Linux and the Mac - and later to mobile phone platforms such as Android and iOS as well as the web.</li>
<li><em>Direct3D</em> - Microsoft's solution to 3D programming, which is Windows only.</li>
</ul>
<h3>OpenGL and WebGL</h3>
<p>As mentioned above, OpenGL is also available for the web in the form of <em>WebGL</em>. In 2009, with increasing interest in full-featured, "desktop-like" web applications, WebGL arrived and allowed development of 3D graphical applications in the web browser using JavaScript. It has been supported in Firefox, for instance, since version 4.</p>
<p>WebGL makes use of a form of OpenGL known as <em>OpenGL ES</em>. OpenGL ES is optimised for devices with limited resources, such as mobile devices (although these days many mobile devices have capabilities comparable with traditional desktop machines!) OpenGL ES programming is slightly different to standard OpenGL: it is somewhat more complex but more efficient. OpenGL ES is also used on Android.</p>
<h3>Higher-level libraries: three.js and A-Frame</h3>
<p>WebGL, however, is a very low-level programming API, and producing even
code to show one single 2D triangle on the screen (never mind a 3D shape)
is rather complex. For this reason, other, higher-level libraries are typically used when doing 3D development for the web;
	<ul>
	<li>First, <a href="https://threejs.org">three.js</a>. three.js arrived on the scene soon after WebGL. three.js hides a lot of the low level details needed to create a 3D scene, allowing you to create and manipulate 3D shapes
with higher-level code. However you still need to manage certain aspects of
your application yourself, such as responding to key presses and updating the
user's position within the 3D world. <strong>We will start looking at three.js this week.</strong></li>
	<li><a href='https://aframe.io'>A-Frame</a> is an even higher-level framework for 3D web development, in which we define our 3D objects (shapes, models and so on) as <em>entities</em>. It comes with components to perform common tasks (such as movement and rotation) automatically. Once we have learnt the fundamentals of 3D development with three.js, we will look at A-Frame.</li>
	</ul>
</p> 
<h2>The OpenGL coordinate system</h2>
<p>Having examined the background behind web 3D graphics, we will now look at some of the fundamental principles of OpenGL development, specifically the coordinate system. Because OpenGL is a 3D graphics API, all shapes we draw need to be specified with three coordinates: x, y and z. In the default OpenGL view, <em>x</em> represents the horizontal axis, <em>y</em> represents the vertical axis and <em>z</em> represents the depth axis:
	<ul>
	<li><em>x</em> increases left to right, as for standard 2D graphics;</li>
	<li><em>y</em> increases <em>upwards</em>.  This is different to the situation in 2D computer graphics, where y increases downwards - but is the same as in standard maths.</li> 
	<li>You can think of the <em>z</em> axis as pointing out at you from the screen, so that positive z coordinates are "in front of the screen" and negative z coordinates are "into the screen". The <em>z</em> coordinate is used to give a sense of depth, so that shapes with negative z will appear smaller and smaller as z becomes more and more negative.</li>
	<li>The <em>origin</em>, where x=0, y=0 and z=0, is in the centre of the screen on the surface of the screen. So areas to the left of the centre of the screen will have negative x, and areas to the right of the screen will have positive x. Likewise, areas above the centre of the screen will have positive y, and areas below the centre of the screen will have negative y. As we saw above, shapes with negative z will appear further and further "back" within the scene as z becomes more and more negative. Because the default view is facing towards negative z, any shapes with <em>positive</em> z will be invisible by default, unless we rotate the default view 180 degrees.</li>
	</ul>

This is shown in the diagram below. </p>
<p><img src="../images/defaultview.png" alt="OpenGL default view"></p>
<h3>World and eye coordinates</h3>
<p>The coordinate system referred to above, with the origin at the centre of the screen, is known as the <em>eye coordinate</em> system because the coordinates are with respect to the user's current view of the world. However, if we are developing a game or an augmented-reality application, we want to give our objects (e.g. game characters, augmented reality content such as Pokemon or points of interest) <em>absolute coordinates</em> within our 3D world. These will not be with respect to the user's current view of the scene, but with respect to the <em>world</em> as a whole, where the <em>world origin</em> might be some specific geographical point, such as the equator or the central room in a game. These objects will be either visible or invisible to the user, depending on where exactly the user is within the world and what direction they are facing. Because we want to place these objects at specific positions within the world, we give them <em>world coordinates</em> - absolute coordinates within the world.</p>
<p>However, the <em>eye</em> coordinates of each object, with respect to the centre of the screen, might be different to the world coordinates. Imagine the origin of the 3D world is the central room in a 3D game. We might not be at that position in the world, we might be in a completely different room, and furthermore, we might not be looking down the negative z-axis as in the default view.  We might be looking in a direction aligned at 45 degrees to both the x and z axes. Additionally, we might be on a slope, in which case, the up direction does not correspond to the y axis.</p>
<p>The eye coordinate (0,0,0) is always the
centre point of the viewport (screen), even if this is not the origin within 
our world. </p>
<h3>The camera</h3>
<p>In many 3D applications, we want to allow the user to navigate through a 3D world. Examples might be the player in a game, or a user navigating the real world in an augmented-reality app. In this case, we define the objects making up the world (which might include 3D buildings, terrain, points of interest, etc) in our code as world coordinates. We then define a <em>camera</em>, which represents the user's position in the world and the direction in which they are facing. Such a camera would have a set of world coordinates defining its position within the world, as well as a rotation. Such a camera, representing the user's position, is known as a <em>first-person camera</em>; other types of camera also exist which present a view of the world from the perspective of something other than the user (e.g. from the perspective of a certain room in a game, or a non-player character).</p>
<p>The <em>world coordinates</em> of the camera would vary, as the camera moves round the world. However, because a first-person camera represents the user's position, its <em>eye coordinates</em> will <em>always</em> be x=0, y=0, z=0.</p>
<h4>Translating and rotating the camera</h4>
<p>As seen above, the camera has a position and rotation. In more detail, it has: 
	<ul>
	<li>A defined position in the world (cx, cy, cz), as world coordinates;</li>
	<li>A defined set of <em>rotations</em> about each of the three axes in our
	world (x, y and z)</li>
	</ul>
By default, the camera is placed at the world origin (cx=0, cy=0, cz=0) and 
faces negative z. In this default position, world coordinates are equal to
eye coordinates. However we can move the camera around the world (e.g. a
player moving around in a game) and rotate it so it faces a direction other 
than negative z. The diagram below (which ignores y coordinates, for 
simplicity, in other words it shows the <em>xz-plane</em> - the flat surface on which every point has y=0) illustrates two such operations:
	<ul>
	<li>Firstly, the camera is translated so that it is at position cx=0, cz=+2;
	</li>
	<li>Secondly, the camera is rotated by 90 degrees anticlockwise.</li>
	</ul>
</p>
<p>
<img src="../images/world_and_eye_coords.png" alt="Moving a camera around, showing the relation between world and eye coordinates" />
</p>
<p>We are going to examine how the <em>eye coordinates</em> of points A and B
change as we move the camera.
	<ul>
	<li>Initially, the eye coordinates of A and B are equal to their world
	coordinates, as the camera is at the default position;</li>
	<li>When we move the camera to cx=0, cz=+2, the <em>difference in z
	coordinates between the camera and the two points increases from 2 to 4.</em>. In other words, <em>with respect to the camera</em>, or in <em>eye coordinates</em> A and B both have z coordinates of -4. The camera is at cz=+2, and still facing negative z, so points A and B both have z coordinates of -4 as they are both in front of the camera and four units away in the <em>z</em> direction. The <em>world</em> z coordinates of A and B, by contrast, are still -2: world coordinates do not change unless the objects move to a different position within the world (e.g. a monster moving in a game)</li>
	<li>We then <em>rotate</em> the camera by 90 degrees anticlockwise. This is done <em>around the y-axis</em> as shown in the diagram below:
<br />
<img src="../images/plane.png" alt="xz-plane and rotating around the y-axis" />
<br />By doing this, the camera is now facing <em>-x</em> in <em>world</em> coordinates. However, in <em>eye</em> coordinates, the camera is still facing -z, as it always does this by definition.</li>
	<li>As a result, A and B are now both to the <em>right</em> of the camera, rather than in front of it. They are still both 4 units away from the camera, as the camera <em>position</em> has not changed (only its rotation), but since they are 4 units <em>to the right</em> of the camera (rather than in front), the <em>eye x coordinate</em> of both is +4 (rather than the eye z coordinate being -4 as was the case originally). Remember that by definition, in eye coordinates, positive x is always to the right.</li>
	<li>The <em>eye z coordinates</em> of A and B will now differ, as A is now in front of the camera and B is behind the camera. Consequently, A will have a negative eye z coordinate and B will have a positive eye z coordinate. As both A and B are two units distance along the eye z axis, it follows that the eye z coordinate of A will be -2 and the eye z coordinate of B will be +2.</li>
	</ul>
</p>
<h4>Don't get confused by the word "camera"!</h4>
<p>It's important to not get confused by the terminology here. The first-person OpenGL camera is <strong>not</strong> the same as the actual hardware camera used to take pictures on the device. When we move onto AR, we will use the term "hardware camera" to distinguish the physical camera from the OpenGL camera.</p>
<h3>Matrices</h3>
<p>Many of you will have come across <em>matrices</em> in the past, either at
school/college or in the first year Mathematical Structures in Computing 
module. <em>Matrices</em> are two-dimensional arrays of numbers which are most commonly used to represent geometric transformations which can be applied to shapes (both 2D and 3D), such as rotation, translation, magnification, stretch and shear. There are also other, more specialised, applications of matrices in science and maths - but these are out of the scope of this module. We will not go into the maths of matrices in great detail, and you will not need to create or multiply matrices yourself (WebGL and three.js take care of this for you) but you need to be aware that a matrix represents a geometric transformation of some kind, such as translation or rotation. You also need to be aware of various matrices which exist within OpenGL which are involved in the rendering process.</p>
<p>If you want to read more on matrices, see <a href='BRIAN_NOTES.pdf'>here</a>.</p>
<h4>The view matrix</h4>
<p>OpenGL defines a matrix which specifies the transformation between the
world coordinates and the eye coordinates.  This is called the <em>view matrix</em>.  Every time you do a translation or rotation in code, the view matrix
is multiplied by the matrix which defines that rotation/translation. Then
finally the coordinates specified in code (the world coordinates) are multiplied by the view matrix to give the coordinates with respect to the user's current view.</p> 
<h4>The projection matrix</h4>
<p>The other type of matrix which is used in OpenGL is the <em>projection matrix</em>. This transforms the coordinates of shapes to add a sense of perspective, in other words it makes nearby shapes appear larger and further-away shapes appear smaller. So, shapes with eye z coordinates close to 0 (e.g. -1, -2) will appear relatively large, whereas shapes with negative z coordinates further from 0 (-10, -20, etc) will appear smaller. Without the projection matrix, no perspective is applied and shapes would appear the same size irrespective of their eye z coordinate.</p>
<hr />
<h2>Beginning three.js programming</h2>
<p>We are now going to begin some basic 3D programming with <em>three.js</em>. As we saw above, three.js is a higher-level library which wraps WebGL, making development easier.</p>
<p>three.js consists of various key objects, which are described below.</p>
<ul>
<li>a <code>scene</code>. The scene represents the 3D scene as a whole.</li>
<li>a <code>camera</code>. As we have seen, the camera represents our current position and orientation within the 3D world.</li>
<li>a <code>renderer</code>. The renderer is responsible for rendering (drawing) the scene to a particular HTML element, typically a canvas.</li>
</ul>
<p>When drawing our 3D objects, we define a series of <strong><code>mesh</code>es</strong>. A <code>mesh</code> is a 3D object within our world and consists of:</p>
<ul>
<li>a <code>geometry</code> describing its geometrical shape, and </li>
<li>a <code>material</code> describing the properties of its surface (for example colour, texture, light reflectance and so on).</li>
</ul>
<p>There are also additional objects we can use in three.js, such as <code>light</code>s: light sources in our world. <code>light</code>s consist of ambient lights (general background lighting) and directional lights (lights placed at a particular position within our world and shining in a particular direction) amongst others. A directional light could be used to simulate the sun, for example.</p>
<h3 id="resources">Resources</h3>
<p>The site <a href="https://threejsfundamentals.org">threejsfundamentais.org</a> is a very good tutorial site for three.js, covering everything from the absolute basics to advanced topics such as AR. Indeed, many of the techniques in this tutorial have been used as a basis for the techniques shown in this week's notes. Furthermore, it comes with interactive tutorials in which you can change the code live in the browser and see the result. In addition, the <a href="https://threejs.org">website</a> contains full API documentation, plus examples.</p>
<h3 id="abasicexample">A basic example</h3>
<p>Here is a basic example of three.js. It simply sets up a scene, it doesn't
draw anything yet. We will start with this HTML:</p>
<pre><code>&lt;!DOCTYPE html&gt;
&lt;html&gt;
&lt;head&gt;
&lt;title&gt;three.js basic example&lt;/title&gt;

&lt;!-- Load the three.js library --&gt;
&lt;script type='text/javascript' src='three.js'&gt;&lt;/script&gt;

&lt;!-- Load your own JavaScript code (shown below) --&gt;
&lt;script type='module' src='index.js'&gt;&lt;/script&gt;

&lt;/head&gt;
&lt;body&gt;
&lt;!-- By default, canvas is 300x150 so we could omit the width and height --&gt;
&lt;canvas id='canvas1' width='300' height='150'&gt;&lt;/canvas&gt;
&lt;/body&gt;
&lt;/html&gt;
</code></pre>
<p>You should download three.js from <a href='https://threejs.org/build/three.js'>here</a> and save it into the folder where you will create your code.</p>
<p>Note how the HTML page contains a <code>&lt;canvas&gt;</code>. The three.js scene will appear
here.</p>
<p>Moving onto the JavaScript (<code>index.js</code>):</p>
<pre>
const canvas = document.getElementById('canvas1');

const camera = new THREE.PerspectiveCamera(40, 2, 0.1, 10000);
const renderer = new THREE.WebGLRenderer({canvas: canvas});
const scene = new THREE.Scene();

requestAnimationFrame(renderScene);

function renderScene() {
    renderer.render(scene, camera);
    requestAnimationFrame(renderScene);
}
</pre>
<p>Note how we create a <code>camera</code> object, a <code>renderer</code> object, and then a <code>scene</code>
object. The camera is a <code>THREE.PerspectiveCamera</code>; why do we need this?</p>
<h4 id="perspective">Perspective</h4>
<p>When creating a scene, we need to account for <em>perspective</em> in order to make nearby objects look larger than further away objects. This is not done by default in WebGL so we have to create a camera which will apply perspective effects. As seen above, this sets up the <em>projection matrix</em> - you may be glad to know that by using three.js we avoid the complex maths necessary to setup the projection matrix! An example is in our code above, as our camera is a <code>THREE.PerspectiveCamera</code>. What do its arguments represent?</p>
<ul>
<li>The first argument is the <em>vertical field of view</em>. This is the field of view,
in degrees, that we can currently see in the scene in the vertical direction (40 degrees here). <strong>Note that people more normally think of the horizontal field of view - the horizontal angle visible in the scene. The vertical field of view can be obtained by dividing the horizontal field of view by the aspect ratio, described below.</strong></li>
<li>The second argument is the <em>aspect ratio</em> - the ratio of width to height. As our canvas is 300x150, we set this to 2 to match the canvas.</li>
<li>the near clip plane (0.1)</li>
<li>the far clip plane (10000).</li>
</ul>
<p>The near and far clip planes define the nearest and
furthest distances that objects can be seen on the screen; here, images closer
than 0.1 units or further than 10000 units away will be invisible. 
The four arguments above define a shape, resembling a sawn-off pyramid, known as the <em>viewing frustum</em>, shown in this diagram.</p>
<p><img src="../images/fig8.png" alt="Viewing frustum" /></p>
<h4 id="therenderer">The renderer</h4>
<p>Next we create our <code>THREE.WebGLRenderer</code>. Note how we create a renderer and associate it with a particular canvas element in our HTML, in this example an element with the ID of <code>canvas1</code>.Having created a renderer we then create our scene.</p>
<h4 id="therenderscenefunction">The renderScene() function</h4>
<p>Note how we handle scene <em>rendering</em>. We need to tell three.js to render
the scene each time the display refreshes. We write a function <code>renderScene()</code> to do the rendering and schedule it using the JavaScript function
<code>requestAnimationFrame()</code> (not part of three.js, but a standard browser API
function). <code>requestAnimationFrame()</code> schedules a function to run before the next browser repaint (<a href="https://developer.mozilla.org/en-US/docs/Web/API/window/requestAnimationFrame">Mozilla</a>).  The idea is we render the scene as often as possible so that if the positions of the camera or the objects change, the scene will update.</p>
<p>In <code>renderScene()</code> we call the three.js <code>renderer</code>'s <code>render()</code> method to render the given <code>scene</code> using the given <code>camera</code>. Then, once we've drawn the scene, we request it to be drawn again with another call to <code>requestAnimationFrame()</code>. Note that <code>requestAnimationFrame()</code> is rather like <code>setTimeout()</code> but has smoother animation as it matches the display refresh rate. It's also a bit like A-Frame's <code>tick()</code> but must be re-called on each rendering, it will not automatically be called repeatedly.</p>
<h3 id="addinga3dobjecttotheexample">Adding a 3D object to the example</h3>
<p>The next example creates a 3D box:</p>
<pre><code>
const canvas = document.getElementById('canvas1');

const camera = new THREE.PerspectiveCamera(80, 2, 0.1, 10000);
const renderer = new THREE.WebGLRenderer({canvas: canvas});
const scene = new THREE.Scene();

const geom = new THREE.BoxGeometry(2,2,2);
const material = new THREE.MeshBasicMaterial({color: 0xff0000});
const mesh = new THREE.Mesh(geom, material);
mesh.position.z = -10;

scene.add(mesh);
requestAnimationFrame(renderScene);

function renderScene() {
    renderer.render(scene, camera);
    requestAnimationFrame(renderScene);
}
</code></pre>
<p>Note how in this example we create a <code>BoxGeometry</code> with dimensions in the 
x, y and z directions of 2 (this is similar to setting the <code>scale</code> in A-Frame).
Then we create a <code>material</code>: the <code>MeshBasicMaterial</code> is a basic material which does not have any special properties for reflecting light, for example. We define its colour: note that we do not use HTML-style colour strings (e.g. <code>"#ff0000"</code>) but instead, a numerical value for the colour. We use hexadecimal (<code>0x</code>) to allow us to define the colour in terms of red, green and blue components: note that <code>0xff0000</code> is equivalent to <code>#ff0000</code>.</p>
<p>Finally we create a <code>mesh</code> using the geometry and material, and add it to the scene.  Note how we set the mesh's <code>position</code>, by setting the <code>z</code> property of its <code>position</code> property. </p>
<p>The rendering function is the same as before.</p>
<h3 id="handlingscreenresizeevents">Handling screen resize events</h3>
<p>The example so far just uses a canvas with a fixed size: width 300, height 150. However, more commonly, particularly on a mobile platform, we need the canvas to <em>adapt</em> to the screen size. So more commonly we will set the canvas to occupy the whole of the screen e.g.:</p>
<pre><code>&lt;canvas id='canvas1' style='display: block; width:100%; height:100%'&gt;&lt;/canvas&gt;
</code></pre>
<p>We also have to, in our CSS, specify that the <code>html</code> and <code>body</code> elements will have a <code>width</code> and <code>height</code> of 100% so that the <code>html</code> (the viewport) and the <code>body</code> (the content) - and thus the canvas, which occupies the whole of the body - will stretch to cover the whole window when the window resizes.</p>
<pre><code>&lt;style&gt;
html, body {
    width: 100%;
    height: 100%;
}
&lt;/style&gt;
</code></pre>
<p>Try modifying your HTML in this way: give the canvas 100% width and height
and add some CSS to set the <code>html</code> and <code>body</code> width and height to 100%.
What happens?</p>
<h4 id="theresult">The result</h4>
<p>You will find that the box appears "blocky" and "pixelated". Why? The 
problem relates to the difference between <em>canvas width and height</em> and <em>CSS width and height</em>. They are two different things. Even though the canvas will have a <em>CSS</em> width and height which covers the whole screen, its <em>canvas</em> width and height will still be 300x150. This is rather like setting the CSS width and height of an image of 300x150 pixels to 100% of the body. The image will still be 300x150 - its resolution will not magically increase - but it will be stretched across the whole of the page so will appear pixelated with poor resolution. Canvases are internally similar to images in HTML - what we are doing is stretching a 300x150 canvas across the entire screen without increasing the resolution of the actual canvas.</p>
<p>This is shown below. Here is a cube image of dimensions 300x150:</p>
<p><img src="../images/cube.png" alt="Unstretched cube image" /></p>
<p>but here is the same image with the CSS width and height set to 900x450
(even though the actual image is still 300x150):</p>
<p><img src="../images/cube.png" alt="Stretched image" style="width: 900px; height: 450px" /></p>
<p>To increase the canvas resolution, we have to reset its <code>width</code> and <code>height</code> properties (these are the canvas width and height) so that they are the same as the CSS width and height of the canvas element. To obtain the <em>CSS</em> width and height of the canvas, we can use <code>canvas.clientWidth</code> and <code>canvas.clientHeight</code>.</p>
<p>What we can then do, in our rendering function, is to test whether the canvas width and height are different to the CSS width and height. If they are (which will occur after a resize), we reset the width and height of the canvas. For example, you can add this code to your <code>renderScene()</code> function:</p>
<pre><code>if(canvas.width != canvas.clientWidth || canvas.height != canvas.clientHeight) {
    renderer.setSize(canvas.clientWidth, canvas.clientHeight, false);
}
</code></pre>
<p>We call the renderer's <code>setSize()</code> method to perform the resizing rather than directly changing the canvas properties, this ensures that three.js keeps track of the changes.</p>
<h3 id="updatingtheaspectratio">Updating the aspect ratio</h3>
<p>Once you've updated the canvas size in the previous example, you will still see a problem. Namely, the cube becomes distorted as you resize the window. This is because you have setup a camera with an aspect ratio of 2 (which it will be by default, due to the default canvas size of 300x150) but the canvas no longer has an aspect ratio of 2. So when the renderer is resized, you have to recalculate the aspect ratio of the canvas and reset the camera's aspect ratio appropriately. This can be done with:</p>
<pre><code>camera.aspect = canvas.clientWidth / canvas.clientHeight;
camera.updateProjectionMatrix();
</code></pre>
<p>The first line should be obvious. The second is perhaps less so. Internally, three.js uses a mathematical <em>matrix</em> known as the <em>projection matrix</em> to represent the perspective; this matrix is used to draw objects with the correct perspective. The projection matrix depends on the properties of the viewing frustum: the aspect ratio, the field of view, and the near and far clip planes. Once we've updated the aspect ratio, we have to update the projection matrix as this will not be done automatically.</p>
<p>Add the code above to your <code>if</code> statement which handles screen resize. You will find that the box appears correctly as a cube even if you resize the window.</p>
<h3 id="theobject3dclass">The Object3D class</h3>
<p>The <code>Object3D</code> class (described <a href="https://threejs.org/docs/index.html#api/en/core/Object3D">here</a>) is a fundamental component of three.js.
<code>Object3D</code> represents a three.js object which can be moved, rotated, 
and scaled. Other three.js objects, such as meshes and cameras, are examples
of <code>Object3D</code>s. Furthermore <code>Object3D</code> forms the key link between three.js and
A-Frame, to be described later.</p>
<h3 id="exercise1">Exercise 1</h3>
<ul>
<li>Change the code so the box is rotated 45 degrees around the y axis, using the mesh's <code>rotation</code> property.</li>
<li>Change the <em>camera</em> position so that it is two units distance from the box along the z axis. The box will appear bigger, because the camera is closer to it. Do not change the position of the box.</li>
</ul>
<h3>Exercise 2</h3>
<ul>
<li>Add buttons to control the camera's x, y and z position. Add these below the canvas. There should be six buttons labelled '-x', '+x', '-y', '+y', '-z' and '+z'. When these are clicked, the camera should move one unit in the appropriate direction. Remember that you can set up an event listener on a button using <code>addEventListener()</code> and passing in an arrow function to handle the event, as follows:
<pre>
document.getElementById("button1").addEventListener("click", e =&gt; {
	// add code to move the camera in here
});
</pre>
</li>
<li>To test it, add new shapes (in addition to the red box)  as follows:
	<ul>
	<li>A blue (0x0000ff) box at x=5, y=0, z=0;</li> 
	<li>A green (0xffff00) sphere of radius 1 at x=0, y=0, z=-5. To create a sphere, use a <code>SphereGeometry</code>, e.g.
	<pre>const geom = new SphereGeometry(radius);</pre>
	where <code>radius</code> is the radius. See <a href='https://threejs.org/docs/?q=geometry#api/en/geometries/SphereGeometry'>here</a> for more detail.</li> 
	<li>A yellow (0x00ff00) cone of radius 1, height 2 at x=-5, y=0, z=0. To create a cone, use a <code>ConeGeometry</code> e.g.
	<pre>const geom = new ConeGeometry(radius, height);</pre>
	where <code>radius</code> is the radius and <code>height</code> is the height. See <a href='https://threejs.org/docs/?q=geometry#api/en/geometries/ConeGeometry'>here</a> for more detail.</li> 
	<li>A magenta (0xff00ff) cylinder of top radius 1, bottom radius 1, and height 2 at x=0, y=0, z=5. To create a cylinder, use a <code>CylinderGeometry</code>, e.g.
	<pre>const geom = new CylinderGeometry(radiusTop, radiusBottom, height);</pre>
	where <code>radiusTop</code> is the radius at the top of the cylinder, <code>radiusBottom</code> is the radius at the bottom of the cylinder, and <code>height</code> is the height. See <a href='https://threejs.org/docs/?q=geometry#api/en/geometries/CylinderGeometry'>here</a> for more detail.</li> 
	</ul>
Try moving along the different axes to see the shapes from different positions.
</li>
<li>Add two more buttons to rotate the camera clockwise and anticlockwise around the y-axis. Note that angles <em>increase anticlockwise</em>; also note <em>radians</em> are used for rotation angles rather than degrees; 180 degrees is equal to PI radians. You can convert between degrees and radians easily using three.js's <code>THREE.Math.degToRad()</code> and <code>THREE.Math.radToDeg()</code> functions, e.g:
<pre>const rad = THREE.Math.degToRad(deg);</pre>
</li>
<li>Test out the rotation functionality to make sure you can rotate the camera to look round the world. <em>Note that you will not yet be able to move forward in the direction the camera is facing;</em>, this requires simple trigonometry and we will consider this next time.</li>
</ul>
</body>
</html>
